# -*- coding: utf-8 -*-
"""2179_review_nlp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p6g1e_wyDh9WVdJnE8gtJd3NqdfbuC2K
"""

import pandas as pd
df = pd.read_csv('Restaurant reviews.csv')
df

# unnecessary column
df.drop(['7514'], axis=1, inplace=True)

df.info()

# check for duplicate value and drop them if necessary
df.duplicated().sum()

df.drop_duplicates(inplace=True)
df.duplicated().sum()

# check for werid value
df['Rating'].value_counts()

# Replace werid values and finish data cleaning
df['Rating'] = df['Rating'].replace(['Like'], '5')
df['Rating'] = df['Rating'].astype(float)

import numpy as np

# data processing
import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline

# metrics
from sklearn.metrics import accuracy_score

# models
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.linear_model import SGDClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from xgboost import XGBClassifier

# for reproducibility
seed = 10086

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Add a new column named "Label", positive for rating greater than or equal to 3 and negative for rating less than 3
df['Label'] = [1 if x >= 3 else 0 for x in df['Rating']]
df

df_new = df[['Review','Label', 'Rating']].copy()
df_new

def preprocess_text(text):
    # remove html tags and keep lowercase alphabetic characters only
    text = re.sub('<[^>]*>', '', text)
    text = re.sub('[^a-zA-Z]', ' ', text).lower()

    # tokenize the words
    words = word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    words = [word for word in words if word not in stop_words]

    # Lemmatize the words
    lemmatizer = WordNetLemmatizer()
    words = [lemmatizer.lemmatize(word) for word in words]

    preprocessed_text = ' '.join(words)
    return preprocessed_text

df_new['clean'] = df_new['Review'].astype(str).apply(preprocess_text)

"""# Textual Analysis"""

from wordcloud import WordCloud
import matplotlib.pyplot as plt

df['Restaurant'].value_counts()

df['clean'] = df['Review'].astype(str).apply(preprocess_text)
df_beyong_fla = df[df['Restaurant'] == 'Beyond Flavours']
review_beyong_fla = ''.join(df_beyong_fla['clean'])
wordss = WordCloud(width=800, height=400, background_color='white').generate(review_beyong_fla)
plt.figure(figsize=(10, 5))
plt.imshow(wordss)
plt.title('Word Cloud for Reviews of Beyongd Flavour')
plt.axis('off')
plt.show()

df_review_neg = df_beyong_fla[df_beyong_fla['Label'] == 0]
review_neg = ''.join(df_review_neg['clean'])
wordcloud_negative = WordCloud(width=800, height=400, background_color='white').generate(review_neg)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_negative)
plt.title('Word Cloud for Negative Reviews for Beyond Flavour')
plt.axis('off')
plt.show()

df_review_pos = df_beyong_fla[df_beyong_fla['Label'] == 1]
review_pos = ''.join(df_review_pos['clean'])
wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(review_pos)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_positive)
plt.title('Word Cloud for Positive Reviews for Beyond Flavour')
plt.axis('off')
plt.show()

df_driven_caf = df[df['Restaurant'] == 'Driven Cafe']
review_driven_caf = ''.join(df_driven_caf['clean'])
wordss = WordCloud(width=800, height=400, background_color='white').generate(review_driven_caf)
plt.figure(figsize=(10, 5))
plt.imshow(wordss)
plt.title('Word Cloud for Reviews of Driven Cafe')
plt.axis('off')
plt.show()

df_driven_caf['Label'].value_counts()

"""---"""

df_review_pos = df_new[df_new['Label'] == 1]
review_pos = ''.join(df_review_pos['clean'])
wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(review_pos)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_positive)
plt.title('Word Cloud for Positive Reviews')
plt.axis('off')
plt.show()

df_review_neg = df_new[df_new['Label'] == 0]
review_neg = ''.join(df_review_neg['clean'])
wordcloud_negative = WordCloud(width=800, height=400, background_color='white').generate(review_neg)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_negative)
plt.title('Word Cloud for Negative Reviews')
plt.axis('off')
plt.show()

df['Rating'].value_counts()

df_review_5star = df_new[df_new['Rating'] == 5]
df_review_5star

review_5star = ''.join(df_review_5star['clean'])
wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(review_5star)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_positive)
plt.title('Word Cloud for Positive Reviews')
plt.axis('off')
plt.show()

"""# Predictive Analysis"""

X = df_new['clean'].values
y = df_new['Label'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=10086)

# setup automatic grid search for different models
model_info = [
    {'model': RandomForestClassifier(random_state=seed),
     'params': {
         'clf__n_estimators': [100, 200],
         'clf__max_depth': [None, 10, 20],}},
    {'model': AdaBoostClassifier(random_state=seed),
     'params': {
         'clf__n_estimators': [50, 100, 150],
         'clf__learning_rate': [1.0, 0.1, 0.01],}},
    {'model': XGBClassifier(random_state=seed, use_label_encoder=False, eval_metric='mlogloss'),
     'params': {
         'clf__max_depth': [3, 5, 6, 7, 10],
         'clf__n_estimators': [100, 150, 200],
         'clf__learning_rate': [0.1, 0.01],}},
    {'model': SGDClassifier(random_state=seed),
     'params': {
         'clf__loss': ['hinge', 'log'],
         'clf__alpha': [1e-4, 1e-3, 1e-2],
         'clf__penalty': ['l2', 'l1', 'elasticnet']}}
    ]

# loop through different models and do grid search on each of them
flag = False
if flag:
    for model_dict in model_info:
        pipeline = Pipeline([
            # Vectorizing text data
            ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,2))),
            ('clf', model_dict['model'])
        ])

        # adjust the parameter grid for the current model
        param_grid = model_dict['params']
        for key in list(param_grid.keys()):
            if not key.startswith('clf__'):
                param_grid['clf__' + key] = param_grid.pop(key)

        grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=1, n_jobs=-1)

        print(f"Training model: {model_dict['model'].__class__.__name__}")
        grid_search.fit(X_train, y_train)

        # use the validation and test data sets to evaluate the model
        best_model = grid_search.best_estimator_
        test_score = best_model.score(X_test, y_test)

        print(f"Model: {model_dict['model'].__class__.__name__}")
        print(f"Test Score: {test_score}")
        print(f"Best Parameters: {grid_search.best_params_}")
        print("-" * 80)